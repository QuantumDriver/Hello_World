{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习简介<br>\n",
    "- 机器学习就是给定一个任务后，通过学习的经验，不断改善对任务的表现。这个过程就叫做机器学习。<br><br>\n",
    "- 机器学习的过程有三个要素：**算法，策略和模型。**另外，数据也非常重要！<br><br>\n",
    "- 数据有很多种类型，离散的或者是连续的，一维的或者是二维的，等等。数据的维度也叫做特征。<br><br>\n",
    "- 所谓算法，就是利用数据来生成模型的一种方法。不同的任务，选择不同的算法，如何选择算法，就要依靠策略。<br><br>\n",
    "- 模型也叫做学习器。比如说利用线性回归这种算法就能得到一个线性回归的模型：y = Ax + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习的种类\n",
    "机器学习通常可以分成四种类型：监督学习，无监督学习，半监督学习和强化学习。这里介绍一下监督学习和非监督学习<br>\n",
    "\n",
    "**监督学习**就是对于算法来说可以给定一个“正确”的数据集，算法产生的预测数据可以跟这个“正确的”数据集做比较。然后可以用“正确的”的数据去纠正“错误”的预测。这就是监督学习。监督学习通常用来做**回归和分类预测。**\n",
    "#### 常见的监督学习算法：\n",
    "- 线性回归，逻辑回归，支持向量机，朴素贝叶斯，K最近邻，决策树，随机森林，集成方法\n",
    "\n",
    "**无监督学习**就是学习的数据并不被特别标识，没有所谓的“正确答案”。学习模型是为了推断出数据的一些内在结构。常见的应用场景包括**关联规则的学习以及聚类等。**\n",
    "#### 常见的无监督学习算法：\n",
    "- 奇异值分解、主成分分析，独立成分分析，Apriori算法，K-Means算法，GMM-EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从策略到模型\n",
    "模型按照我的个人理解，其实就是一个数学方程式，例如: y = ax + b。这就属于是线性模型，当然模型还有其他各种各样的形式。显而易见的是，模型中最关键的未知数就是模型的参数，以线性模型为例子，我们知道x和y是什么，所以要求出a和b这两个参数来。有了这两个参数我们就能构建好模型，然后根据新的输入x，去输出预测的y。<br><br>\n",
    "模型的好坏可以通过**损失函数**来衡量，损失函数的作用在于，计算模型产生的预测值和数据中正确值的差距。计算这种差距的方法有很多种，常见的有：\n",
    "- 平方损失函数，绝对损失函数，对数损失函数<br>\n",
    "\n",
    "显然，损失值越小，说明模型拟合得越好，我们输入数据让模型不断学习的目的，就是为了选择出最好的模型。如果我们已经知道了损失函数的形式，那么我们将**损失值最小化**即可求出想要的模型，但这里会出现一些问题。简单来说就是**过拟合**：\n",
    "- 如果单纯地最优化损失值，会使得模型复杂度过高，即模型完美地匹配了训练数据，但无法准确估计新数据。这就是过拟合。\n",
    "- **为了减少过拟合，需要加入惩罚项，也叫做正则化**。例如 y = ax + b，惩罚项就会作用在a上。\n",
    "- 权衡了损失值和模型复杂度之后的模型往往对于预测新数据有较好的能力。\n",
    "\n",
    "训练误差为0这看起来很美好，但实际上并不可取，因为训练数据本身存在噪声。训练误差为0的模型复杂度非常高，预测能力很差。对于模型的选择，我们更希望的是模型能有更好的预测能力，即能够使得测试误差最小，这才是学习的目的。一般有正则化和交叉验证两种方法使得测试误差最小。<br>\n",
    "\n",
    "**正则化**，其实就是在损失函数里面价格正则项防止参数过拟合，正则项有L1正则和L2正则两种，L1可以使得不重要的参数归零，因为其求导之后只有+1或-1，可以稳步向0前进。而L2则不能，因为L2会下降的越来越慢，但L2有一个好处是计算起来非常方便。<br>\n",
    "\n",
    "**交叉验证**，交叉验证说白了就是把数据集分成两部分，一部分用来训练，一部分用来测试。比如可以把70%的数据当作训练集，30%的数据当作测试集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估\n",
    "\n",
    "**分类问题**是机器学习的核心，对于一个二分类问题来说，如果要评价一个模型分类分得好不好，通常用精确率和召回率来评价。假设我们关注的是正类，不关注的是负类。那么模型可能把正类预测为负类，也可能把负类预测为正类。所以有四种情况：\n",
    "- TP 把正类分为正类\n",
    "- FN 把正类分为负类\n",
    "- FP 把负类分为正类\n",
    "- TN 把负类分为负类\n",
    "\n",
    "**精确率(查准率)就是P = TP／(TP + FP)**，即所有被分为正类的数据中，正类分类正确的比率。\n",
    "\n",
    "**召回率(查全率)就是R = TP／(TP + FN)**，即所有真正是正类的数据中，正类分类正确的比率。\n",
    "\n",
    "此外还有**F1值，F1 = 2TP／(2TP + FP + FN)**，当精确率和召回率都高时，F1值也会高。\n",
    "\n",
    "我们可以根据机器学习的预测结果对样例进行排序，排在前面的就是学习器认为最可能的是正例的样本，后面的则是最不可能是正例的样本。按这个顺序对样本作为正例进行预测，则每次可以计算出当前查全率和查准率。我们以查准率和纵轴，查全率和横轴，就能绘制出一条曲线，简称**PR曲线**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Capture.png](https://i.postimg.cc/vm9vXR9v/Capture.png)](https://postimg.cc/7CH7YWKC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PR曲线如上图所示，三条线分别代表不同的学习器所取得的效果，如果A能把C完全包住，则说明学习器A比学习器C要好。如果两条线发生了交叉，可以比较平衡点的取值，即是查全率等于查准率时的值，除了比较平衡点以后，最经常比较的就是F1的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个常见的评价曲线就是**ROC曲线**，它与PR曲线类似，首先将学习器认为最可能的是正例的样本排在前面，不可能的排在后面，样本根据可能性排序，这个可能性就是阈值，这里的阈值用于求对应的:\n",
    "- TPR(真正例率) = TP/(FN+TP)预测为正实际为正的样本占所有正样本的比例。\n",
    "- FPR(假正例率) = TN/(TN+FP)预测为负实际为负的样本占所有负样本的比例。\n",
    "\n",
    "显然，从大到小的可能性代表了**从大到小的阈值**，不同的阈值计算出多组（FPR,TPR）坐标点，把这些点放在图上，就是："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Capture1.png](https://i.postimg.cc/pXXFGm3T/Capture1.png)](https://postimg.cc/z36v3GzZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC曲线下方的面积就是AUC，AUC值越大代表模型效果越好\n",
    "我们可以**从AUC来判断分类器（预测模型）是好还是坏**：\n",
    "\n",
    "- AUC = 1，完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。\n",
    "- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，有预测价值。\n",
    "- AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。\n",
    "- AUC < 0.5，比随机猜测还差，但只要将预测反过来就能优于随机猜测。\n",
    "\n",
    "相对来说，**ROC曲线的评价比PR曲线的评价更为稳健**，如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Capture2.png](https://i.postimg.cc/vmRDsT25/Capture2.png)](https://postimg.cc/Hr2T0YgL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果负样本增加的话，可以看出，P-R曲线发生了明显的变化，**而ROC曲线形状基本不变**。这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。这有什么实际意义呢？在很多实际问题中，正负样本数量往往很不均衡。比如，计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的1/1000甚至1/10000。\n",
    "\n",
    "若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则能够更加稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。但需要注意的是，**选择P-R曲线还是ROC曲线是因实际问题而异的**，如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
